{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cbdd0b96559d5e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-30T09:35:22.064168Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from audio_utils import *\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4fd30a1a8f0f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:42:12.997293Z",
     "start_time": "2024-06-27T16:42:12.992408Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. sample_rate is 8000\n",
    "target_sample_rate = 8000\n",
    "# 2. vad_window_ms is 30ms\n",
    "vad_window_ms = [10, 20, 30][2]\n",
    "# 3. vad_overlap_percent is 50%\n",
    "vad_overlap_ratio = 0.5\n",
    "# 4. label_region_ms is 100ms\n",
    "label_region_s = 0.1\n",
    "# 5. label_overlap_percent is 50%\n",
    "label_overlap_ratio = 0.5\n",
    "# 6. decision_function_name is \"max\"\n",
    "deciding_method = [\"max\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6fdbf9523ce23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:42:13.544451Z",
     "start_time": "2024-06-27T16:42:13.526863Z"
    }
   },
   "outputs": [],
   "source": [
    "class WebrtcVadLabelMaker:\n",
    "    @staticmethod\n",
    "    def max_count_deciding(items) -> bool:\n",
    "        counts = np.bincount(items)\n",
    "        return bool(np.argmax(counts))\n",
    "\n",
    "    VAD_WIDTHS = [10, 20, 30]\n",
    "\n",
    "    def __init__(self, mode=2, vad_window_ms=30, vad_overlap_ratio=0, deciding_method='max'):\n",
    "        self.vad_window_ms = vad_window_ms\n",
    "        self.vad_overlap_ratio = vad_overlap_ratio\n",
    "        self.vad = webrtcvad.Vad(mode)\n",
    "        \n",
    "        self.DECIDING_FUNCTIONS_DICT = {'max': WebrtcVadLabelMaker.max_count_deciding}\n",
    "        self.decider = self.DECIDING_FUNCTIONS_DICT[deciding_method]\n",
    "\n",
    "    def __call__(self, au: AudioWorker, label_region_sec=0.1, label_overlap_ratio=0.5):\n",
    "        simple_wave = au.wave.squeeze(0)\n",
    "        vad_window = int(self.vad_window_ms * au.rate / 1000)\n",
    "        vad_hop = int(vad_window * self.vad_overlap_ratio)\n",
    "        frames = torch.nn.functional.unfold(simple_wave.unsqueeze(0).unsqueeze(0).unsqueeze(-1),\n",
    "                                            kernel_size=(vad_window, 1),\n",
    "                                            stride=(vad_hop, 1)).squeeze(0).T\n",
    "        speech_mask = []\n",
    "        for frame in frames:\n",
    "            bytes_like = frame.mul(32767).to(torch.int16).numpy().tobytes()\n",
    "            is_speech = self.vad.is_speech(bytes_like, au.rate)\n",
    "            speech_mask.append(is_speech)\n",
    "\n",
    "        item_wise_mask = np.full_like(simple_wave, False, dtype=bool)\n",
    "        for i, is_speech in enumerate(speech_mask):\n",
    "            item_wise_mask[vad_hop * i:vad_hop * i + vad_window] = is_speech or item_wise_mask[\n",
    "                                                                                vad_hop * i:vad_hop * i + vad_window]\n",
    "        reg_width = int(au.rate * label_region_sec)\n",
    "        region_hop_width = int(reg_width * (1 - label_overlap_ratio))\n",
    "        count = int(np.floor((len(item_wise_mask) - reg_width) / region_hop_width) + 1)\n",
    "        region_labels = []\n",
    "        for i in range(count):\n",
    "            start = i * region_hop_width\n",
    "            end = min((i + 1) * region_hop_width, len(item_wise_mask))\n",
    "            reg_is_speech = self.decider(item_wise_mask[start:end])\n",
    "            region_labels.append(reg_is_speech)\n",
    "\n",
    "        return item_wise_mask, region_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f0353eee9da988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:42:17.533715Z",
     "start_time": "2024-06-27T16:42:14.177684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000_30_50_100_50_max\n"
     ]
    }
   ],
   "source": [
    "openSLR_data_directory = 'OpenSLR/train-clean-100'\n",
    "\n",
    "vad = WebrtcVadLabelMaker(2, vad_window_ms, vad_overlap_ratio, deciding_method)\n",
    "\n",
    "audio_files_paths = OpenSLRDataset.get_files_by_extension(openSLR_data_directory, ext='flac')\n",
    "\n",
    "labels_dir = f'{target_sample_rate}_{vad_window_ms}_{int(vad_overlap_ratio * 100)}_{int(label_region_s * 1000)}_{int(label_overlap_ratio * 100)}_{deciding_method}'\n",
    "\n",
    "print(labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec8fc383f9551dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:04:12.855691Z",
     "start_time": "2024-06-27T16:42:17.535671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28539/28539 [18:40<00:00, 25.46it/s]\n"
     ]
    }
   ],
   "source": [
    "if len(audio_files_paths) > 0:\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    for audio_path in tqdm(audio_files_paths, total=len(audio_files_paths)):\n",
    "        aw = AudioWorker(os.path.join(openSLR_data_directory, audio_path)).load()\n",
    "        _, labels = vad(aw)\n",
    "        \n",
    "        destination_file_path = OpenSLRDataset.change_file_extension(os.path.join(labels_dir, audio_path), \".txt\")\n",
    "        label_dir, file_name = os.path.split(destination_file_path)\n",
    "        \n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        with open(destination_file_path, 'w') as file:\n",
    "            file.write(''.join(map(str, list(map(int, labels)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6399139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mynameis.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audio_utils import *\n",
    "OpenSLRDataset.change_file_extension(\"mynameis.file\", \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb51239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
