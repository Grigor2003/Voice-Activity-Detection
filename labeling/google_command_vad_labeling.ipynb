{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbdd0b96559d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:27:51.348211Z",
     "start_time": "2025-01-29T15:27:49.661354Z"
    }
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import webrtcvad\n",
    "import contextlib\n",
    "import soundfile as sf\n",
    "import scipy.io.wavfile as wav\n",
    "import resampy\n",
    "\n",
    "from other.utils import get_files_by_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fdbf9523ce23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:27:51.504776Z",
     "start_time": "2025-01-29T15:27:51.499143Z"
    }
   },
   "outputs": [],
   "source": [
    "class WebrtcVadLabelMaker:\n",
    "    @staticmethod\n",
    "    def resample_pcm_wav(file_path, target_sr, output_path=None):\n",
    "        \"\"\"\n",
    "        Reads a PCM-formatted WAV file, resamples if the sample rate differs from target_sr,\n",
    "        and saves the output as a PCM WAV file.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path: str, path to the input WAV file.\n",
    "        - target_sr: int, target sample rate (Hz).\n",
    "        - output_path: str (optional), path to save the resampled WAV file.\n",
    "                    If None, the output is saved as \"<original_filename>_resampled.wav\" in the same directory.\n",
    "        \"\"\"\n",
    "        # Read original wav file\n",
    "        orig_sr, data = wav.read(file_path)\n",
    "\n",
    "        # Check if resampling is needed\n",
    "        if orig_sr == target_sr:\n",
    "            if output_path is None:\n",
    "                output_path = f\"{os.path.splitext(file_path)[0]}_copy.wav\"\n",
    "            wav.write(output_path, orig_sr, data)\n",
    "            return\n",
    "\n",
    "        # Convert data to float32 for processing. PCM int16 data ranges -32768 to 32767.\n",
    "        data_float = data.astype(np.float32)\n",
    "        if data.dtype == np.int16:\n",
    "            data_float /= 32768.0  # Normalize to roughly [-1, 1)\n",
    "\n",
    "        # Resample the data.\n",
    "        # Handle mono and multi-channel audio:\n",
    "        if data_float.ndim == 1:\n",
    "            data_resampled = resampy.resample(data_float, orig_sr, target_sr)\n",
    "        else:\n",
    "            # For multi-channel, resample each channel separately.\n",
    "            channels = []\n",
    "            for ch in range(data_float.shape[1]):\n",
    "                ch_resampled = resampy.resample(data_float[:, ch], orig_sr, target_sr)\n",
    "                channels.append(ch_resampled)\n",
    "            # Stack channels back into a 2D array (samples x channels)\n",
    "            data_resampled = np.stack(channels, axis=-1)\n",
    "\n",
    "        # Convert resampled data back to int16.\n",
    "        # Scale the float data back to the int16 range and clip to avoid overflow.\n",
    "        data_resampled = np.clip(data_resampled * 32768, -32768, 32767).astype(np.int16)\n",
    "\n",
    "        # Determine the output path if not provided.\n",
    "        if output_path is None:\n",
    "            base, ext = os.path.splitext(file_path)\n",
    "            output_path = f\"{base}_resampled.wav\"\n",
    "\n",
    "        # Save the resampled file.\n",
    "        wav.write(output_path, target_sr, data_resampled)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_wave(path, target_sr=None):\n",
    "        ext = os.path.splitext(path)[1]\n",
    "        if ext == '.wav':\n",
    "            with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "                comp_type = wf.getcomptype()\n",
    "                assert comp_type == 'NONE'\n",
    "            WebrtcVadLabelMaker.resample_pcm_wav(path, target_sr, path)\n",
    "            with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "                num_channels = wf.getnchannels()\n",
    "                assert num_channels == 1\n",
    "                sample_width = wf.getsampwidth()\n",
    "                assert sample_width == 2\n",
    "                sample_rate = wf.getframerate()\n",
    "                assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "                pcm_data = wf.readframes(wf.getnframes())\n",
    "                return pcm_data, sample_rate\n",
    "        elif ext == '.flac':\n",
    "            with sf.SoundFile(path, \"r\") as flac_file:\n",
    "                pcm_data = flac_file.read(dtype=\"int16\").tobytes()\n",
    "                sample_rate = flac_file.samplerate\n",
    "                assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "                num_channels = flac_file.channels\n",
    "                assert num_channels == 1\n",
    "                return pcm_data, sample_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def find_ones_regions(arr, threshold=0):\n",
    "        diff = np.diff(arr)\n",
    "        starts = np.where(diff == 1)[0] + 1  # +1 because diff shifts left\n",
    "        ends = np.where(diff == -1)[0]\n",
    "\n",
    "        # Handle edge cases\n",
    "        if arr[0] == 1:\n",
    "            starts = np.insert(starts, 0, 0)\n",
    "        if arr[-1] == 1:\n",
    "            ends = np.append(ends, len(arr) - 1)\n",
    "\n",
    "        # Ensure starts and ends are the same length\n",
    "        if len(starts) != len(ends):\n",
    "            raise ValueError(\"Mismatch between starts and ends\")\n",
    "\n",
    "        # Flatten the starts and ends into a single list\n",
    "        result = []\n",
    "        for s, e in zip(starts, ends):\n",
    "            if e - s < threshold:\n",
    "                continue\n",
    "            result.extend([s, e])\n",
    "\n",
    "        if len(result) > 2:\n",
    "            result = [result[0], result[-1]]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __init__(self, mode=2, vad_window_ms=30, min_region_ms=30, vad_overlap_ratio=0, target_sample_rate=16000, decider_function=None):\n",
    "        self.vad_window_ms = vad_window_ms\n",
    "        self.vad_overlap_ratio = vad_overlap_ratio\n",
    "        self.vad = webrtcvad.Vad(mode)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.decider_function = decider_function\n",
    "        self.min_region_ms = min_region_ms\n",
    "\n",
    "    def __call__(self, file_path):\n",
    "        wave, rate = WebrtcVadLabelMaker.read_wave(file_path, target_sr=self.target_sample_rate)\n",
    "        if rate != self.target_sample_rate:\n",
    "            print(f\"{file_path} has a rate of {rate} instead of {self.target_sample_rate}\")\n",
    "            return\n",
    "        window = int(self.vad_window_ms * rate / 1000)\n",
    "        step = int((1 - self.vad_overlap_ratio) * window)\n",
    "\n",
    "        samples_count = len(wave) // 2\n",
    "        samples_pred_sum = np.zeros(len(wave), dtype=np.float32)\n",
    "        samples_pred_count = np.zeros(len(wave), dtype=np.float32)\n",
    "\n",
    "        n_frames = int((samples_count - window) / step)\n",
    "        for i in range(n_frames):\n",
    "            s = i * step\n",
    "            e = s + window\n",
    "            is_speech = self.vad.is_speech(wave[2 * s:2 * e], rate)\n",
    "            samples_pred_sum[s:e] += is_speech\n",
    "            samples_pred_count[s:e] += 1\n",
    "\n",
    "        samples_pred = (samples_pred_sum / (samples_pred_count + 1e-8)) >= 0.5\n",
    "        ones_regions = self.find_ones_regions(samples_pred.astype(np.int32), threshold=self.min_region_ms * rate / 1000)\n",
    "\n",
    "        return ones_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4fd30a1a8f0f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:27:51.353528Z",
     "start_time": "2025-01-29T15:27:51.350220Z"
    }
   },
   "outputs": [],
   "source": [
    "target_sample_rate = 8000\n",
    "vad_window_ms = [10, 20, 30][2]\n",
    "vad_overlap_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0353eee9da988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:28:20.572575Z",
     "start_time": "2025-01-29T15:28:19.751360Z"
    }
   },
   "outputs": [],
   "source": [
    "openSLR_data_directory, ext = 'datasets/google_commands_v2', 'wav'\n",
    "# openSLR_data_directory, ext = \"../data/MSDWild/raw_wav\", 'wav'\n",
    "where_to_save = 'buffer'\n",
    "\n",
    "vad = WebrtcVadLabelMaker(\n",
    "    mode=2,\n",
    "    vad_window_ms=vad_window_ms,\n",
    "    vad_overlap_ratio=vad_overlap_ratio, \n",
    "    target_sample_rate=target_sample_rate,\n",
    "    min_region_ms=60)\n",
    "\n",
    "audio_files_paths = get_files_by_extension(openSLR_data_directory, ext=ext, rel=True)\n",
    "\n",
    "labels_path = f'{vad.target_sample_rate}_{vad.vad_window_ms}_{int(vad.vad_overlap_ratio * 100)}_webrtc_labels.csv'\n",
    "labels_path = os.path.join(where_to_save, labels_path)\n",
    "data_samples = len(audio_files_paths)\n",
    "print(data_samples, \"files like:\", np.random.choice(audio_files_paths))\n",
    "print(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8fc383f9551dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:29:51.317536Z",
     "start_time": "2025-01-29T15:28:22.512495Z"
    }
   },
   "outputs": [],
   "source": [
    "if data_samples > 0:\n",
    "    with open(labels_path, 'w') as file:\n",
    "        file.write(\"filename,labels\" + '\\n')\n",
    "\n",
    "        t = tqdm(audio_files_paths, total=data_samples)\n",
    "        webrtcvad_t, write_t = 0, 0\n",
    "        ma = 0.8\n",
    "        for i, audio_path in enumerate(t):\n",
    "            s_vad = time()\n",
    "            filepath = os.path.join(openSLR_data_directory, audio_path)\n",
    "            one_stamps = vad(filepath)\n",
    "            if one_stamps is None:\n",
    "                continue\n",
    "            e_vad = time()\n",
    "            path_parts = audio_path.split(os.sep)\n",
    "            filename = path_parts[-1]\n",
    "\n",
    "\n",
    "            file.write(filepath + ',' + '-'.join(map(str, one_stamps)) + '\\n')\n",
    "            e_write = time()\n",
    "\n",
    "            webrtcvad_t = ma * webrtcvad_t + (1 - ma) * (e_vad - s_vad)\n",
    "            write_t = ma * webrtcvad_t + (1 - ma) * (e_write - e_vad)\n",
    "            if i % 100 == 0:\n",
    "                t.set_description_str(f\"webrtcvad: {webrtcvad_t * 1000:.1f}ms | write: {write_t * 1000:.1f}ms\")\n",
    "\n",
    "else:\n",
    "    print(len(audio_files_paths), \"audio files not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255df167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(labels_path)\n",
    "\n",
    "problematics = df[df.isnull().any(axis=1)].filename.values.tolist()\n",
    "problematics = set(os.path.basename(problematic).split('_')[0] for problematic in problematics)\n",
    "len(problematics)\n",
    "\n",
    "mask = df['filename'].apply(lambda x: any(p in x for p in problematics))\n",
    "\n",
    "df = df[~mask]\n",
    "df.to_csv(labels_path.replace('.csv', '_filtered.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vad_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
