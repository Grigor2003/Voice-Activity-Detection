{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:05:31.844723Z",
     "start_time": "2025-01-29T15:05:31.841200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "\n",
    "from other.data.audio_utils import get_files_by_extension\n",
    "from other.data.audio_utils import AudioWorker"
   ],
   "id": "87cbdd0b96559d5e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:24:11.472240Z",
     "start_time": "2025-01-29T15:24:11.468427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from_dir = r\"../../../datasets/train-clean-100-16k\"\n",
    "ext = \"flac\"\n",
    "target_sample_rate = 8000"
   ],
   "id": "cb4fd30a1a8f0f5c",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:24:41.360971Z",
     "start_time": "2025-01-29T15:24:32.552369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_files_paths = get_files_by_extension(from_dir, ext=ext, rel=True)\n",
    "upscaled_count = 0\n",
    "data_samples = len(audio_files_paths)\n",
    "\n",
    "print(data_samples, \"files like:\", np.random.choice(audio_files_paths))\n",
    "\n",
    "to_dir = from_dir + f\"(converted to {target_sample_rate} sr)\"\n",
    "print(\"Created |\", to_dir)\n",
    "\n",
    "for audio_path in tqdm(audio_files_paths):\n",
    "    full_path = os.path.join(from_dir, audio_path)\n",
    "    aw = AudioWorker(full_path).load()\n",
    "    upscaled_count += aw.rate < target_sample_rate\n",
    "    if aw.rate != target_sample_rate:\n",
    "        aw.resample(to_freq=target_sample_rate)\n",
    "\n",
    "    create_dir = os.path.join(to_dir, os.path.dirname(audio_path))\n",
    "    os.makedirs(create_dir, exist_ok=True)\n",
    "    create_path = os.path.join(create_dir, os.path.basename(audio_path))\n",
    "    torchaudio.save(create_path, aw.wave, aw.rate)\n",
    "\n",
    "print(f\"{upscaled_count} upscales were made\")\n"
   ],
   "id": "41bc3eca2fc9574c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28539 files like: 5322\\7678\\5322-7678-0031.flac\n",
      "Created | ../data/train-clean-100(converted to 8000 sr)(converted to 8000 sr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2317/28539 [00:07<01:30, 289.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(create_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     19\u001B[0m     create_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(create_dir, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(audio_path))\n\u001B[1;32m---> 20\u001B[0m     \u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwave\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mupscaled_count\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m upscales were made\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:313\u001B[0m, in \u001B[0;36mget_save_func.<locals>.save\u001B[1;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, backend, compression)\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Save audio data to file.\u001B[39;00m\n\u001B[0;32m    237\u001B[0m \n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03mNote:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    310\u001B[0m \n\u001B[0;32m    311\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    312\u001B[0m backend \u001B[38;5;241m=\u001B[39m dispatcher(uri, \u001B[38;5;28mformat\u001B[39m, backend)\n\u001B[1;32m--> 313\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits_per_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompression\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:44\u001B[0m, in \u001B[0;36mSoundfileBackend.save\u001B[1;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, compression)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compression:\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoundfile backend does not support argument `compression`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m \u001B[43msoundfile_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits_per_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbits_per_sample\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:457\u001B[0m, in \u001B[0;36msave\u001B[1;34m(filepath, src, sample_rate, channels_first, compression, format, encoding, bits_per_sample)\u001B[0m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m channels_first:\n\u001B[0;32m    455\u001B[0m     src \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mt()\n\u001B[1;32m--> 457\u001B[0m \u001B[43msoundfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamplerate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\soundfile.py:366\u001B[0m, in \u001B[0;36mwrite\u001B[1;34m(file, data, samplerate, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001B[0m\n\u001B[0;32m    362\u001B[0m     channels \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    363\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SoundFile(file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, samplerate, channels,\n\u001B[0;32m    364\u001B[0m                subtype, endian, \u001B[38;5;28mformat\u001B[39m, closefd,\n\u001B[0;32m    365\u001B[0m                compression_level, bitrate_mode) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 366\u001B[0m     \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\soundfile.py:1068\u001B[0m, in \u001B[0;36mSoundFile.write\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1066\u001B[0m \u001B[38;5;66;03m# no copy is made if data has already the correct memory layout:\u001B[39;00m\n\u001B[0;32m   1067\u001B[0m data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mascontiguousarray(data)\n\u001B[1;32m-> 1068\u001B[0m written \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_array_io\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwrite\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m written \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(data)\n\u001B[0;32m   1070\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_frames(written)\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\soundfile.py:1394\u001B[0m, in \u001B[0;36mSoundFile._array_io\u001B[1;34m(self, action, array, frames)\u001B[0m\n\u001B[0;32m   1392\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mitemsize \u001B[38;5;241m==\u001B[39m _ffi\u001B[38;5;241m.\u001B[39msizeof(ctype)\n\u001B[0;32m   1393\u001B[0m cdata \u001B[38;5;241m=\u001B[39m _ffi\u001B[38;5;241m.\u001B[39mcast(ctype \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m, array\u001B[38;5;241m.\u001B[39m__array_interface__[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m-> 1394\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cdata_io\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\Voice-Activity-Detection\\.venv\\Lib\\site-packages\\soundfile.py:1403\u001B[0m, in \u001B[0;36mSoundFile._cdata_io\u001B[1;34m(self, action, data, ctype, frames)\u001B[0m\n\u001B[0;32m   1401\u001B[0m     curr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m   1402\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(_snd, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msf_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m action \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m ctype)\n\u001B[1;32m-> 1403\u001B[0m frames \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1404\u001B[0m _error_check(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_errorcode)\n\u001B[0;32m   1405\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "93f7d0779b69d443"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
